训练数据构造：
```
python dialog_knowledge_explicitly_appending_heuristic_method.py --knowledge_sep [UNK] --knowledge_end [CLS] --goal_stage_sep [SEP] --m
ax_history_length 200 --force_history True
```

# 基于朴素知识匹配的mBART模型解决面向推荐的对话任务

## 成果

截止2020年4月28日榜上第四名

## 相关工作

表格到文本的转换，即结构化文本到非结构化文本的转换，可使用Seq2Seq模型进行。然而，其可靠性不尽如人意，容易出现无中生有、忽略不计的问题。

BART是Facebook提出的类transformer的seq2seq预训练模型。最近，又提出了多语言的mBART。

## 方法

### 1. 实体与信息替换

```
输入：[' 旺池川菜（青岛万象城店）'，'评分'，'3.3']['旺池川菜（青岛万象城店）'，'人均价格'，'67']['旺池川菜（青岛万象城店）'，'地址'，'市南区山东路10号万象城L543（香港中路）']这你都知道，它那人均价格是多少呢，地址在哪呢？评分怎么样呢？

输出：这家店的地址是人均价格是是是地址是是位于南关区金州路10号广场4楼，评分是5
```

鉴于原始文本训练时模型生成出现不准确现象，故进行实体与信息替换。在知识与对话中，将推荐的三类实体餐厅、电影、歌曲分别替换成restaurant_no, movie_ no, song_no，身高、体重、评分、地址、人均价格信息分别替换成height、weight、rating、address、expense。提交时，再替换回来。这样，可保证生成文本实体与信息的准确度。我们可以很方便地在goal中找到要推荐的进行替换。

### 2. 匹配知识

每条知识形如[实体, 关系,信息]，实体可直接匹配，关系可用打表法匹配，表如下：

```
eq_relations = {
    '星座': [],
    '血型': [],
    '属相': ['属 啥', '属 什么', ],
    '成就': [],
    '主演': ['谁 演 的'],
    '类型': ['什么 歌'],
    '评论': [],  # ['唱 的 咋样', '评价', '好听 吗'],
    '导演': ['谁 导 的'],
    '简介': ['介绍', '信息'],
    '演唱': ['谁 唱 的', '主唱', '谁 的 歌'],
    '身高': ['多高', '多 高'],
    '体重': ['多重'],
    '获奖': ['哪些 奖', '什么 成就'],
    '口碑': [],
    '生日': ['什么 时候 出生', '哪 年 出生', '哪年 出生', '哪一年 出生', '的 出生 ', '出生日期', '多会 出生'],
    '出生地': ['哪里 的 人', '哪儿 的 人', '哪里 出生', '在 哪 出生', '哪儿 出生', '哪 的', '哪里 的 籍贯', '哪里 人', '出生 地区', '出生 在 哪里'],
    '国家地区': ['国家 地区', '哪个 国家'],
    '人均价格': ['人均 价格', '消费 怎么样', '人均 消费', '平均价格'],
    '地址': ['在 哪', '具体位置'],
    '评分': [],
    '特色菜': [],
    '日期': [],  # '问 日期' in goal[0]
    '时间': [],  # '问 时间' in goal[0]
    '新闻': ['故事'],
    '天气': []
}
```

较短的信息可直接匹配，但是出生地信息例外，只需出现除“中国”外的部分即可（如“谢娜是哪的人？”	”她是四川人哦。“ ['谢娜', '出生地', '中国   四川   德阳']）；较长的信息部分匹配中即算匹配。此外，注意到将知识向量与问题向量点乘计算相似度的方法并不能很好的适用于诸如\[“她是哪儿的？”][‘她’, ‘出生地’]这样的情形。

### 3. 知识翻转

鉴于存在诸如”这部电影谁导的？"这类问题，需要进行知识翻转以方便知识挑选。对于知识[实体, 关系,信息]，若关系为生日、演唱、导演、主演、星座，则翻转知识为[信息, 关系,实体]。注意到这些信息实际上也可以看成实体。

### 4. 训练数据构造

考虑单轮对话，输出为机器人的回答，输入包含用户档案（用户姓名，用户性别，用户年龄范围）、聊天情况（聊天时间、聊天日期、聊天背景）、知识及用户发言。机器人主动寒暄时，输入为用户档案与聊天情况；否则，为知识及用户发言。若某条知识的信息出现在机器人回答中，且实体或关系出现在此轮对话或之前的对话中，则认为这条知识应用于此轮对话，将其添加到输入中。

### 5. 测试数据构造

形式与训练数据构造一致，但是因机器人回答未知，知识匹配的方法有所不同。考虑用户提问的知识匹配，只需关系出现在用户提问，且实体出现在用户提问或之前对话中即可。考虑“适合吃”的知识匹配，只要“适合吃”的前提条件出现在对话中即可。考虑推荐的知识匹配，从goal中提出推荐实体，若判断正处于或即将处于推荐这一实体阶段，将某条评论作为推荐。

### 6. 确保中文标点使用

鉴于mBART是多语言模型，生成时采用英文标点如逗号、感叹号、问号、括号、摄氏度符号，需要替换成中文标点。这是较为关键的。

## 实验与结果分析

在单个NVIDIA Tesla V100训练8小时，共14个epoch，测试输出生成用时6分钟。对于测试输出进行实体与信息反替换，未替换实体检查，英文标点替换，天气温度数值检查，重复检查等，最后提交。test1榜单排名第4，score 1.408，F1 53.81，BLEU 0.479/0.392。

本模型表现远超基线，也与榜单后的其他模型表现拉开较大的差距，但仍与榜单前三名存在一定差距。原因可能是尚未较好地补全测试goal序列，难以得到要推荐的实体，进而选择评论加入输入，甚至出现例如应该推荐某部电影，却因无知识输入，模型凭空编造出推荐某首歌曲的现象，由于这首歌曲未被实体替换，进而更不可能被实体反替换，从而很容易地被发现到了。此外，gaol中只表明挑选某条评论作为推荐理由，而评论各式各样，理应筛选一番，但我们尚未考虑，有可能挑选出不适合推荐的评论（如'天津 话 啊   跑来跑去 的'，'时光 网上 居然 没有 这个 片子 的 资料 ， 为什么 ？'）作为输入。此外模型也可能未采用给定评论进行生成，而是泛泛而谈”这是一部不错的片子/歌曲“之类，或者使用训练时学习到的对于其他电影的推荐理由。
